---
phase: 05-project-management
plan: 05
type: execute
wave: 3
depends_on: [05-01, 05-02]
files_modified:
  - libs/domain/src/data_source.rs
  - libs/domain/src/lib.rs
  - libs/db/src/repo/pg_data_source.rs
  - apps/api/src/routes/data_sources.rs
  - apps/api/src/services/storage_service.rs
autonomous: true

must_haves:
  truths:
    - "DataSource entity exists with typed ID"
    - "CRUD endpoints at /api/v1/projects/:id/data-sources"
    - "Cloud storage connection test works"
    - "Credentials stored encrypted"
  artifacts:
    - path: "libs/domain/src/data_source.rs"
      provides: "DataSource domain entity"
      contains: "pub struct DataSource"
    - path: "apps/api/src/routes/data_sources.rs"
      provides: "Data source API endpoints"
      contains: "pub fn router"
---

<objective>
Create DataSource domain entity, repository, and API for configuring data sources.

Purpose: Allow users to configure where task data comes from - file uploads, S3, GCS, Azure Blob, or external APIs. Support credential storage and connection testing.

Output: DataSource entity, repository, REST API, and storage service for cloud connections.
</objective>

<context>
@.planning/phases/05-project-management/05-RESEARCH.md (object_store patterns)
@.planning/phases/05-project-management/05-CONTEXT.md (data source decisions)
@libs/domain/src/ (entity patterns)
@apps/api/src/routes/ (route patterns)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DataSource domain and repository</name>
  <files>libs/domain/src/data_source.rs, libs/domain/src/lib.rs, libs/db/src/repo/pg_data_source.rs</files>
  <action>
1. Create libs/domain/src/data_source.rs:

Define DataSourceId with typed_id! macro (prefix: "dsrc_")

Define DataSourceType enum:
```rust
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, sqlx::Type)]
#[sqlx(type_name = "data_source_type", rename_all = "snake_case")]
#[typeshare]
pub enum DataSourceType {
    FileUpload,
    S3,
    Gcs,
    AzureBlob,
    Api,
}
```

Define ValidationMode enum:
```rust
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, sqlx::Type)]
#[sqlx(type_name = "validation_mode", rename_all = "snake_case")]
#[typeshare]
pub enum ValidationMode {
    Strict,
    Lenient,
}
```

Define DataSource struct:
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
#[typeshare]
pub struct DataSource {
    pub id: DataSourceId,
    pub project_id: ProjectId,
    pub name: String,
    pub source_type: DataSourceType,
    pub config: DataSourceConfig,
    pub validation_mode: ValidationMode,
    pub last_sync_at: Option<DateTime<Utc>>,
    pub item_count: i32,
    pub error_count: i32,
    pub is_active: bool,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}
```

Define DataSourceConfig enum:
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
#[typeshare]
pub enum DataSourceConfig {
    FileUpload { 
        allowed_extensions: Vec<String>,
        max_file_size_mb: i32,
    },
    S3 {
        bucket: String,
        region: String,
        prefix: Option<String>,
        use_iam_role: bool,
    },
    Gcs {
        bucket: String,
        prefix: Option<String>,
        use_workload_identity: bool,
    },
    AzureBlob {
        container: String,
        account: String,
        prefix: Option<String>,
        use_managed_identity: bool,
    },
    Api {
        endpoint: String,
        auth_type: ApiAuthType,
        headers: HashMap<String, String>,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[typeshare]
pub enum ApiAuthType {
    None,
    ApiKey { header_name: String },
    Bearer,
    Basic,
}
```

Define CreateDataSource and UpdateDataSource DTOs

2. Create libs/db/src/repo/pg_data_source.rs:

Define DataSourceRepository trait with CRUD operations
Implement PgDataSourceRepository:
- Store config as JSONB
- Handle credentials in separate table (not returned in normal queries)
- Filter by project_id
  </action>
  <verify>
Run `cargo check -p glyph-domain glyph-db` - compiles.
TypeScript types generated.
  </verify>
</task>

<task type="auto">
  <name>Task 2: Create storage service and data source routes</name>
  <files>apps/api/src/services/storage_service.rs, apps/api/src/routes/data_sources.rs</files>
  <action>
1. Create apps/api/src/services/storage_service.rs:

```rust
use object_store::{ObjectStore, aws::AmazonS3Builder, gcp::GoogleCloudStorageBuilder, azure::MicrosoftAzureBuilder};

pub struct StorageService;

impl StorageService {
    /// Test connection to cloud storage
    pub async fn test_connection(
        config: &DataSourceConfig,
        credentials: Option<&Credentials>,
    ) -> Result<ConnectionTestResult, StorageError> {
        match config {
            DataSourceConfig::S3 { bucket, region, prefix, use_iam_role } => {
                let mut builder = AmazonS3Builder::new()
                    .with_bucket_name(bucket)
                    .with_region(region);
                
                if !use_iam_role {
                    if let Some(creds) = credentials {
                        // Add credentials
                    }
                }
                
                let store = builder.build()?;
                // Try to list with limit 1 to test
                let _ = store.list(prefix.as_ref().map(|p| p.as_str().into()))
                    .next().await;
                
                Ok(ConnectionTestResult { success: true, message: "Connected".into() })
            }
            // Similar for GCS, Azure...
            _ => Ok(ConnectionTestResult { success: true, message: "No test needed".into() })
        }
    }
    
    /// List files in data source
    pub async fn list_files(
        config: &DataSourceConfig,
        credentials: Option<&Credentials>,
        limit: usize,
    ) -> Result<Vec<FileInfo>, StorageError> {
        // Implementation using object_store
    }
}

#[derive(Debug, Serialize)]
pub struct ConnectionTestResult {
    pub success: bool,
    pub message: String,
}

#[derive(Debug, Serialize)]
pub struct FileInfo {
    pub path: String,
    pub size: u64,
    pub modified: Option<DateTime<Utc>>,
}
```

2. Create apps/api/src/routes/data_sources.rs:

```rust
pub fn router() -> Router<AppState> {
    Router::new()
        .route("/", get(list_data_sources).post(create_data_source))
        .route("/:id", get(get_data_source).put(update_data_source).delete(delete_data_source))
        .route("/:id/test", post(test_connection))
        .route("/:id/files", get(list_files))
        .route("/:id/credentials", put(update_credentials))
        .route("/:id/sync", post(trigger_sync))
}
```

Note: These routes are nested under /projects/:project_id/data-sources

Implement handlers:
- list_data_sources: Filter by project_id from path
- create_data_source: Validate project exists, user has permission
- test_connection: Use StorageService::test_connection
- list_files: Preview files in data source
- update_credentials: Encrypt and store credentials
- trigger_sync: Placeholder for Phase 7 (returns 501 for now)

Credential encryption:
- Use a simple encryption approach for now (can enhance later)
- Store encrypted in data_source_credentials table
- Never return credentials in API responses
  </action>
  <verify>
Run `cargo check -p glyph-api` - compiles.
Test connection endpoint with mock S3 bucket.
  </verify>
</task>

</tasks>

<verification>
1. Domain types compile and have TypeScript types
2. Repository handles config as JSONB
3. Routes compile and respond correctly
4. Connection test works for S3 (mock or real)
5. Credentials not exposed in API responses
</verification>

<success_criteria>
- DataSource entity with typed ID (dsrc_)
- DataSourceConfig handles all source types
- CRUD endpoints at /projects/:id/data-sources
- Connection test endpoint works
- Credentials stored securely (encrypted)
- list_files returns file metadata
</success_criteria>
